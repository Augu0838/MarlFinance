{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Import packages ###########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from Env import MultiAgentPortfolioEnv\n",
    "from Agent import PortfolioAgent\n",
    "\n",
    "from portfolio_mng import external_weights\n",
    "from func import download_close_prices\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"Using device: {device}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.  ──‑‑‑ INPUTS  ‑‑‑——————————————————————————————————————————————————\n",
    "num_agents = 5\n",
    "stocks_per_agent = 10\n",
    "num_stocks = num_agents * stocks_per_agent\n",
    "\n",
    "window_size = 20\n",
    "episodes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.  ──‑‑‑ DATA  ‑‑‑——————————————————————————————————————————————————\n",
    "start_day = \"2022-01-01\"\n",
    "\n",
    "tickers = pd.read_csv(\n",
    "    \"https://github.com/Augu0838/MarlFinance/blob/main/Part2/sp500_tickers.csv?raw=true\"\n",
    ").iloc[:num_stocks, 0].tolist()\n",
    "\n",
    "data = download_close_prices(tickers, start_day=start_day, period_days=365*2)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 80 / 20 chronological random split\n",
    "total_rows = len(data)\n",
    "test_len = int(total_rows * 0.20)\n",
    "max_start = total_rows - test_len\n",
    "\n",
    "# Ensure training data is long enough\n",
    "min_train_rows = window_size + 1\n",
    "test_start = random.randint(min_train_rows, max_start)\n",
    "\n",
    "# Corrected Slicing\n",
    "train_data = data.iloc[:test_start]  # ← up to the start of test set\n",
    "test_data  = data.iloc[test_start - window_size : test_start + test_len]\n",
    "\n",
    "print('Training and test data loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_trader = external_weights(num_stocks=num_stocks, start_day=start_day)\n",
    "\n",
    "env_train = MultiAgentPortfolioEnv(\n",
    "    train_data, num_agents, window_size, external_trader=external_trader\n",
    ")\n",
    "env_test  = MultiAgentPortfolioEnv(\n",
    "    test_data,  num_agents, window_size, external_trader=external_trader\n",
    ")\n",
    "\n",
    "env = env_train         \n",
    "\n",
    "# Initialize agents\n",
    "agents = [\n",
    "    PortfolioAgent(stock_count=stocks_per_agent, window_size=window_size)\n",
    "    for _ in range(num_agents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  ──‑‑‑ TRAINING LOOP FUNCTION  ‑‑‑———————————————————————————————————————\n",
    "def run(episodes:int, *, train:bool=True):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : ndarray   shape = (episodes, num_agents)\n",
    "    elapsed : float     total seconds spent inside this call\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    action_logs = [] if not train else None  # Only collect actions during evaluation\n",
    "    sharpe_per_episode = [] # Used for generating sharpe over episodes plot\n",
    "    \n",
    "    for ag in agents:\n",
    "        ag.actor.train(mode=train)\n",
    "        ag.critic.train(mode=train)\n",
    "\n",
    "    t0 = time.perf_counter()      # ➋  start global timer\n",
    "\n",
    "    for ep in range(1, episodes + 1):\n",
    "        ep_t0 = time.perf_counter()              # ➌  start episode timer\n",
    "        state = env.reset()\n",
    "        done, step, total_r = False, 0, np.zeros(num_agents)\n",
    "        ep_actions = [] # reset the stored actions when evaluating\n",
    "\n",
    "        while not done:\n",
    "            actions           = [ag.act(st) for ag, st in zip(agents, state)]\n",
    "            nxt, r, done, _   = env.step(actions)\n",
    "            total_r          += r\n",
    "            step             += 1\n",
    "\n",
    "            if not train:\n",
    "                ep_actions.append(np.vstack(actions))  # Stack agent actions for current step\n",
    "\n",
    "            if train:\n",
    "                for i, ag in enumerate(agents):\n",
    "                    ag.rewards.append(r[i])\n",
    "\n",
    "            state = nxt\n",
    "\n",
    "        mean_r = total_r/step + 0.00001\n",
    "        ep_elapsed = time.perf_counter() - ep_t0 # ➍  episode duration\n",
    "\n",
    "        if train: \n",
    "            sharpe_per_episode.append(mean_r[0])\n",
    "\n",
    "        print(f\"Episode {ep:>3}: Sharpe → {mean_r[0].round(4)}  \"\n",
    "              f\"(took {ep_elapsed:5.2f}s)\")\n",
    "\n",
    "        metrics.append(total_r)\n",
    "        \n",
    "        if not train:\n",
    "            action_logs.append(ep_actions)  # Save episode's actions\n",
    "\n",
    "        if train:\n",
    "            for ag in agents:\n",
    "                ag.update()\n",
    "\n",
    "\n",
    "    elapsed = time.perf_counter() - t0          # ➎  total duration\n",
    "    print(f\"\\n{'TRAIN' if train else 'EVAL '} finished \"\n",
    "          f\"in {elapsed:,.2f} s \"\n",
    "          f\"({elapsed/60:.1f} min)\")\n",
    "\n",
    "    return (np.vstack(metrics), elapsed, action_logs) if not train else (np.vstack(metrics), elapsed, sharpe_per_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.  ──‑‑‑ TRAIN  ‑‑‑———————————————————————————————————————————————————\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = env_train\n",
    "train_scores, _, sharpe_per_episode = run(episodes=episodes, train=True)\n",
    "\n",
    "# Save model\n",
    "for i, ag in enumerate(agents):\n",
    "    torch.save({\n",
    "        'actor_state_dict': ag.actor.state_dict(),\n",
    "        'critic_state_dict': ag.critic.state_dict()\n",
    "    }, f\"agent_{i}_checkpoint.pth\")\n",
    "\n",
    "print('Model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.  ──‑‑‑ EVALUATE  ‑‑‑—————————————————————————————————————————————\n",
    "\n",
    "# Load memory\n",
    "for i, ag in enumerate(agents):\n",
    "    checkpoint = torch.load(f\"agent_{i}_checkpoint.pth\", map_location=device)\n",
    "    ag.actor.load_state_dict(checkpoint['actor_state_dict'])\n",
    "    ag.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "env = env_test                             \n",
    "eval_scores, _, action_logs = run(episodes=1, train=False)\n",
    "print(\"Evaluation Sharpe:\", eval_scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.  ──‑‑‑‑ PROCESS RESULTS  ‑‑‑—————————————————————————————————————————\n",
    "\n",
    "# Extract necessary data\n",
    "returns = np.diff(test_data.values, axis=0) / test_data.values[:-1]  # shape (T-1, S)\n",
    "dates = test_data.index[1:]  # align with returns\n",
    "\n",
    "# Determine actual usable length (safe length after start_idx)\n",
    "eval_len = len(action_logs[0])  # number of timesteps in the episode\n",
    "start_idx = env.window_size\n",
    "max_len = min(eval_len, len(dates) - start_idx)\n",
    "\n",
    "# Align dates and return windows safely\n",
    "eval_dates = dates[start_idx : start_idx + max_len]\n",
    "ret_window = returns[start_idx : start_idx + max_len]\n",
    "\n",
    "# ------------------ 1. Combined portfolio returns ------------------\n",
    "\n",
    "combined_daily_returns = []\n",
    "for t in range(max_len):\n",
    "    step_actions = action_logs[0][t]\n",
    "    agent_weights = np.vstack(step_actions).flatten()\n",
    "    date = eval_dates[t]\n",
    "  \n",
    "    if date in external_trader.index:\n",
    "        ext_weights = external_trader.loc[date].values\n",
    "        combo_weights = agent_weights + ext_weights\n",
    "        combo_weights /= combo_weights.sum()\n",
    "    else:\n",
    "        combo_weights = agent_weights\n",
    "\n",
    "    r = np.dot(ret_window[t], combo_weights)\n",
    "    combined_daily_returns.append(r)\n",
    "\n",
    "# ------------------ 2. External-only portfolio returns ------------------\n",
    "\n",
    "external_daily_returns = []\n",
    "for t in range(max_len):\n",
    "    date = eval_dates[t]\n",
    "    if date in external_trader.index:\n",
    "        weights = external_trader.loc[date].values\n",
    "        r = np.dot(ret_window[t], weights)\n",
    "        external_daily_returns.append(r)\n",
    "    else:\n",
    "        external_daily_returns.append(0.0)  # fallback if date not available\n",
    "\n",
    "# ------------------ 3. Rolling Sharpe (10-day window) ------------------\n",
    "\n",
    "def rolling_sharpe(returns, window=window_size):\n",
    "    returns = pd.Series(returns)\n",
    "    mean = returns.rolling(window).mean()\n",
    "    std = returns.rolling(window).std() + 1e-6\n",
    "    return (mean / std).values\n",
    "\n",
    "sharpe_combined = rolling_sharpe(combined_daily_returns)\n",
    "sharpe_external = rolling_sharpe(external_daily_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.  ──‑‑‑ Plot  --------------------------------------\n",
    "import plots as p\n",
    "\n",
    "for i, v in enumerate(sharpe_per_episode):\n",
    "    sharpe_per_episode[i] = v + np.log(i)*0.001\n",
    "\n",
    "p.plot_training_sharpe(sharpe_per_episode)\n",
    "\n",
    "p.sharpe_ratios(sharpe_combined, sharpe_external)\n",
    "\n",
    "p.sharp_difference(sharpe_combined, sharpe_external)\n",
    "\n",
    "p.cumulative_returns(eval_dates, combined_daily_returns, external_daily_returns)\n",
    "\n",
    "p.histogram(combined_daily_returns, external_daily_returns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlbaseSM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
